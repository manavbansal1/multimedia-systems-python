{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "22cfedde",
      "metadata": {
        "id": "22cfedde"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import heapq\n",
        "from queue import PriorityQueue\n",
        "# Please put your input file in the same folder as this Jupyter notebook file.\n",
        "# Please do not change any other code\n",
        "# You only need to complete the functions with TODO\n",
        "# You can simply run the Q1/Q2/Q3_test() to test your function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8039925",
      "metadata": {
        "id": "e8039925"
      },
      "outputs": [],
      "source": [
        "def Q1_input(file_path):\n",
        "    input_list = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            values = line.strip().split(',')\n",
        "            if len(values) == 3:\n",
        "                try:\n",
        "                    Y = int(values[0])\n",
        "                    Co = int(values[1])\n",
        "                    Cg = int(values[2])\n",
        "                    input_list.append((Y, Co, Cg))\n",
        "                except ValueError:\n",
        "                    print(f\"Invalid line: {line}\")\n",
        "    return input_list\n",
        "\n",
        "\n",
        "def Q1_test():\n",
        "    input_file = \"q1_input.txt\"\n",
        "    yco_cg_list = Q1_input(input_file)\n",
        "\n",
        "    for Y, Co, Cg in yco_cg_list:\n",
        "        YUV = Q1(Y, Co, Cg)\n",
        "        print(f\"YCoCg: ({Y}, {Co}, {Cg}) -> YUV: (Y={YUV[0]}, U={YUV[1]}, V={YUV[2]})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e296e743",
      "metadata": {
        "id": "e296e743"
      },
      "outputs": [],
      "source": [
        "def Q1(Y, Co, Cg):\n",
        "    # TODO:\n",
        "    # Conversion formula from Y Co Cg to YUV\n",
        "    \n",
        "    # Convertin Cg Y Co to GBR \n",
        "    CgYCo = np.array([[Cg], [Y], [Co]])\n",
        "    matrix1 = np.array([[1, 1, 0], \n",
        "                        [-1, 1, -1], \n",
        "                        [-1, 1, 1]])\n",
        "    # print(matrix1) # Debugging\n",
        "    GBR = np.matmul(matrix1, CgYCo)\n",
        "    # print(GBR) # Debugging\n",
        "\n",
        "    # Convert GBR to RGB\n",
        "    RGB = np.array([[GBR[2][0]], [GBR[0][0]], [GBR[1][0]]])\n",
        "    # print(RGB) # Debugging\n",
        "\n",
        "    # Conversion matrix from RGB to YUV\n",
        "    matrix2 = np.array([[0.299, 0.587, 0.114],\n",
        "                        [-0.299, -0.587, 0.886],\n",
        "                        [0.701, -0.587, -0.114]])\n",
        "    # print(matrix2) # Debugging\n",
        "\n",
        "    # Convert RGB to YUV\n",
        "    YUV = np.matmul(matrix2, RGB)\n",
        "\n",
        "    # Extracting Y, U, V from YUV matrix \n",
        "    Y = YUV[0][0]\n",
        "    U = YUV[1][0]\n",
        "    V = YUV[2][0]\n",
        "\n",
        "    # print(Y, U, V) # Debugging\n",
        "    # return YUV values\n",
        "    return (Y, U, V)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "35e43085",
      "metadata": {
        "id": "35e43085",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YCoCg: (100, 5, 5) -> YUV: (Y=101.795, U=-11.795000000000002, V=-1.7950000000000035)\n"
          ]
        }
      ],
      "source": [
        "Q1_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb4cf90f",
      "metadata": {
        "id": "fb4cf90f"
      },
      "outputs": [],
      "source": [
        "dither_matrix = np.array([\n",
        "    [0, 3],\n",
        "    [2, 1]\n",
        "])\n",
        "\n",
        "def Q2_input(file_path):\n",
        "    image = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            row = []\n",
        "            values = line.strip().split(',')\n",
        "            for item in values:\n",
        "                row.append(int(item))\n",
        "            image.append(row)\n",
        "    return np.array(image)\n",
        "\n",
        "def Q2_test():\n",
        "    file_path = \"q2_input.txt\"\n",
        "    input_image = Q2_input(file_path)\n",
        "    print(\"input image:\\n\",input_image)\n",
        "    dithering_res = dithering(input_image,dither_matrix)\n",
        "    ordered_dithering_res = ordered_dithering(input_image,dither_matrix)\n",
        "    print(\"dithering:\\n\",dithering_res)\n",
        "    print(\"ordered_dithering:\\n\",ordered_dithering_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "db8656ac",
      "metadata": {
        "id": "db8656ac"
      },
      "outputs": [],
      "source": [
        "def dithering(input_image, dither_matrix):\n",
        "\n",
        "    \"\"\"\n",
        "    IMPLEMENTATION OF DITHERING\n",
        "    Added Support for any n*n dither matrix for extra 1 mark\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Normalize the input image to range 0-4\n",
        "    # Assuming input_image is 0-255, map to 0-4 (5 levels for a 2x2 matrix)\n",
        "    intensity_level = dither_matrix.shape[0] * dither_matrix.shape[1] + 1  # 5\n",
        "    normalized_image = np.floor((input_image / 256) * intensity_level).astype(int)\n",
        "    # print(\"Normalized image:\\n\", normalized_image) # Debugging\n",
        "\n",
        "    normalized_image[normalized_image > 4] = 4  # Cap the values to 4\n",
        "    # print(\"Capped normalized image:\\n\", normalized_image) # Debugging\n",
        "    \n",
        "    # Step 2: Define output image size (2N x 2N)\n",
        "    n_rows, n_cols = input_image.shape\n",
        "    d_rows, d_cols = dither_matrix.shape  # 2x2\n",
        "    output_rows = n_rows * d_rows\n",
        "    output_cols = n_cols * d_cols\n",
        "    output_image = np.zeros((output_rows, output_cols), dtype=int)\n",
        "    # print(f\"Output image size: {output_rows}x{output_cols}\") # Debugging\n",
        "\n",
        "\n",
        "    # Step 3: Expand each pixel into a 2x2 block\n",
        "    for i in range(n_rows):\n",
        "        for j in range(n_cols):\n",
        "            # Get the normalized value of the current pixel\n",
        "            k = normalized_image[i, j]\n",
        "            # print(f\"Processing pixel ({i}, {j}) with normalized value {k}\") # Debugging\n",
        "\n",
        "            # Compare k to each value in the dither_matrix to get a 2x2 binary block\n",
        "            submatrix = (k > dither_matrix).astype(int)\n",
        "            # print(f\"Generated 2x2 block for pixel ({i}, {j}):\\n\", submatrix) # Debugging\n",
        "            # Place the 2x2 block in the output image\n",
        "            output_image[i*d_rows:(i+1)*d_rows, j*d_cols:(j+1)*d_cols] = submatrix\n",
        "    \n",
        "    # print(\"Final output image:\\n\", output_image) # Debugging\n",
        "    return output_image\n",
        "\n",
        "def ordered_dithering(input_image,dither_matrix):\n",
        "    #TODO:\n",
        "    # Function for ordered dithering\n",
        "    output_image = np.zeros_like(input_image)\n",
        "\n",
        "    # Get the size of the dither matrix (assuming it's square)\n",
        "    n = dither_matrix.shape[0]\n",
        "    # print(f\"Dither matrix size: {n}x{n}\")  # Debugging\n",
        "    \n",
        "    # Calculate the number of intensity levels based on dither matrix size\n",
        "    # For a 2x2 matrix, values might be 0-3, so intensity_level = 5 (0 to 4)\n",
        "    intensity_level = dither_matrix.size + 1  # n^2 + 1\n",
        "    # print(f\"Intensity levels: {intensity_level}\")  # Debugging\n",
        "\n",
        "    # Normalize the input image from 0-255 to 0-(intensity_level-1)\n",
        "    # For example, for a 2x2 matrix, map 0-255 to 0-4\n",
        "    normalized_image = np.floor((input_image / 256) * intensity_level).astype(int)\n",
        "    normalized_image[normalized_image > 4] = 4  # Cap the values to 4\n",
        "    # print(\"Capped normalized image:\\n\", normalized_image) # Debugging\n",
        "\n",
        "    # Tile the dither matrix to match the input image size\n",
        "    # Calculate the number of times to repeat the dither matrix in each dimension\n",
        "    reps_x = input_image.shape[0] // n\n",
        "    reps_y = input_image.shape[1] // n\n",
        "    tiled_dither = np.tile(dither_matrix, (reps_x, reps_y))\n",
        "    \n",
        "    # Ensure the tiled dither matrix matches the input image size exactly\n",
        "    # (This assumes the image dimensions are divisible by n, as per some problem constraints)\n",
        "    tiled_dither = tiled_dither[:input_image.shape[0], :input_image.shape[1]]\n",
        "    # print(\"Tiled dither matrix:\\n\", tiled_dither)  # Debugging\n",
        "\n",
        "    # Apply ordered dithering: compare normalized image to tiled dither matrix\n",
        "    output_image = (normalized_image > tiled_dither).astype(int)\n",
        "    # print(\"Final output image:\\n\", output_image)  # Debugging\n",
        "\n",
        "    return output_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "01197452",
      "metadata": {
        "id": "01197452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input image:\n",
            " [[  5 266]\n",
            " [ 52   5]]\n",
            "dithering:\n",
            " [[0 0 1 1]\n",
            " [0 0 1 1]\n",
            " [1 0 0 0]\n",
            " [0 0 0 0]]\n",
            "ordered_dithering:\n",
            " [[0 1]\n",
            " [0 0]]\n"
          ]
        }
      ],
      "source": [
        "Q2_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "71279cb3",
      "metadata": {
        "id": "71279cb3"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "def Q3_input(file_path):\n",
        "    string = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            string.append(line)\n",
        "    return string\n",
        "\n",
        "\n",
        "def Q3_test():\n",
        "\n",
        "    file_path = \"q3_input.txt\"\n",
        "\n",
        "    input_list = Q3_input(file_path)\n",
        "    for input_string in input_list:\n",
        "        print(\"input string: \",input_string)\n",
        "        print(\"first order entropy:\",first_order_entropy(input_string))\n",
        "        print(\"second order entropy:\",second_order_entropy(input_string))\n",
        "        print(\"average codeword length:\",huffman_length(input_string))\n",
        "        print(\"joint average length:\",joint_huffman_length(input_string))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce4fe6e",
      "metadata": {
        "id": "dce4fe6e"
      },
      "outputs": [],
      "source": [
        "def first_order_entropy(string):\n",
        "    # TODO:\n",
        "    # Function to calculate first-order entropy\n",
        "    freq = Counter(string)\n",
        "    total = len(string)\n",
        "    entropy = 0\n",
        "    for count in freq.values():\n",
        "        p = count / total\n",
        "        if p > 0:\n",
        "            entropy -= p * math.log2(p)\n",
        "    return entropy\n",
        "\n",
        "def second_order_entropy(string):\n",
        "    # TODO:\n",
        "    # Function to calculate second-order entropy\n",
        "    if len(string) < 2:\n",
        "        print(\"String too short for second-order entropy.\")\n",
        "        return 0  # Not enough data for second-order entropy.\n",
        "\n",
        "    biGramFrequencyMap = {}\n",
        "    totalBigrams = 0\n",
        "\n",
        "    for i in range(0, len(string) - 1, 2):  # Increment by 2 for non-overlapping pairs\n",
        "        biGram = string[i:i + 2]\n",
        "        biGramFrequencyMap[biGram] = biGramFrequencyMap.get(biGram, 0) + 1\n",
        "        totalBigrams += 1\n",
        "        # print(f\"Found bigram: {biGram}, Count: {biGramFrequencyMap[biGram]}\") # Debugging\n",
        "    \n",
        "    # print(\"\\nBigram Frequency Map:\", biGramFrequencyMap) # Debugging\n",
        "    # print(\"Total Bigrams Processed:\", totalBigrams) # Debugging\n",
        "\n",
        "    entropy = 0.0\n",
        "    for frequency in biGramFrequencyMap.values():\n",
        "        probability = frequency / totalBigrams\n",
        "        entropy += probability * math.log2(probability)\n",
        "        # print(f\"Bigram: {bigram}, Frequency: {frequency}, Probability: {probability:.4f}, Contribution: {probability * math.log2(probability):.4f}\") # Debugging\n",
        "\n",
        "    return -entropy / 2  # Divide by 2 to get the average entropy per symbol pair\n",
        "\n",
        "class SymbolNode:\n",
        "    def __init__(self, symbol, freq):\n",
        "        self.symbol = symbol\n",
        "        self.freq = freq\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.freq < other.freq\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return self.left is None and self.right is None\n",
        "\n",
        "def create_frequency_dict(text, order):\n",
        "    \"\"\"Create a frequency dictionary for symbols or pairs based on the order.\"\"\"\n",
        "    freq_map = {}\n",
        "    step = order  # Step size for non-overlapping pairs\n",
        "    for i in range(0, len(text) - order + 1, step):\n",
        "        symbol = text[i:i + order]\n",
        "        freq_map[symbol] = freq_map.get(symbol, 0) + 1\n",
        "        # print(f\"Found symbol: {symbol}, Count: {freq_map[symbol]}\")  # Debugging\n",
        "    return freq_map\n",
        "\n",
        "def build_priority_queue(freq_map):\n",
        "   # Build a priority queue based on the frequency map\n",
        "    pq = []\n",
        "    for symbol, freq in freq_map.items():\n",
        "        heapq.heappush(pq, SymbolNode(symbol, freq))\n",
        "    return pq\n",
        "\n",
        "def merge_nodes(pq):\n",
        "    # Merge nodes in the priority queue to form the Huffman tree.# \n",
        "    while len(pq) > 1:\n",
        "        left = heapq.heappop(pq)  # Get the node with the smallest frequency\n",
        "        right = heapq.heappop(pq)  # Get the next smallest node\n",
        "        merged = SymbolNode(None, left.freq + right.freq)  # Merge the two nodes into one\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "        heapq.heappush(pq, merged)  # Insert the merged node back into the queue\n",
        "    return pq[0] if pq else None\n",
        "\n",
        "def calculate_tree_depth_and_length(node, depth):\n",
        "    # Calculate total length of the Huffman tree.# \n",
        "    if node is None:\n",
        "        return 0\n",
        "    if node.is_leaf():\n",
        "        return node.freq * depth  # If it's a leaf, add the weighted depth\n",
        "    return calculate_tree_depth_and_length(node.left, depth + 1) + calculate_tree_depth_and_length(node.right, depth + 1)\n",
        "\n",
        "def build_huffman_tree(text, order):\n",
        "\n",
        "    # Build the Huffman tree and calculate the average codeword length\n",
        "    # for either single-symbol or 2-symbol joint Huffman coding.\n",
        "    \n",
        "    # Step 1: Create frequency map for pairs (or single symbols if order=1)\n",
        "    freq_map = create_frequency_dict(text, order)\n",
        "\n",
        "    # Step 2: Build priority queue based on frequencies\n",
        "    pq = build_priority_queue(freq_map)\n",
        "\n",
        "    # Step 3: Merge nodes to form the tree\n",
        "    root = merge_nodes(pq)\n",
        "    if root is None:\n",
        "        print(\"Error: Empty tree, no Huffman code generated.\")\n",
        "        return 0\n",
        "\n",
        "    # Step 4: Calculate total codeword length (weighted sum of depths)\n",
        "    total_length = calculate_tree_depth_and_length(root, 0)\n",
        "\n",
        "    if order == 1:\n",
        "        # For single-symbol Huffman coding, we divide by the total number of symbols\n",
        "        avg_codeword_length_per_symbol = total_length / len(text)\n",
        "    elif order == 2:\n",
        "        # For 2-symbol joint Huffman coding, we divide by the number of pairs\n",
        "        num_pairs = len(text) // 2\n",
        "        avg_codeword_length_per_pair = total_length / num_pairs\n",
        "        avg_codeword_length_per_symbol = avg_codeword_length_per_pair / 2  # since each pair has 2 symbols\n",
        "\n",
        "    return avg_codeword_length_per_symbol\n",
        "\n",
        "def huffman_length(string):\n",
        "    avg_length = build_huffman_tree(string, 1)  # Call with order=1 for single symbols\n",
        "    return avg_length\n",
        "\n",
        "def joint_huffman_length(string):\n",
        "    joint_avg_length = build_huffman_tree(string, 2)  # Call with order=2 for 2-symbol pairs\n",
        "    return joint_avg_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "da8ebaf5",
      "metadata": {
        "id": "da8ebaf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input string:  AABB\n",
            "first order entropy: 1.0\n",
            "second order entropy: 0.5\n",
            "average codeword length: 1.0\n",
            "joint average length: 0.5\n"
          ]
        }
      ],
      "source": [
        "Q3_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RHRVy3PFS0GA",
      "metadata": {
        "id": "RHRVy3PFS0GA"
      },
      "outputs": [],
      "source": [
        "# (3) Discuss any issues/interesting observations in your implementation.\n",
        "\n",
        "\"\"\"\n",
        "1. Handling Non-overlapping Pairs:\n",
        "In the implementation for second-order (joint) coding, the string is split into non-overlapping 2‑symbol pairs. An interesting point was ensuring that the string length is even so that every pair is complete. In cases where the string length might be odd, a decision must be made (e.g., padding or ignoring the last symbol). In our assignment, the string is always an even number greater than 2, so this issue did not arise.\n",
        "\n",
        "2. Entropy Calculations:\n",
        "\n",
        "First-order entropy is computed by considering the probability of each individual letter.\n",
        "Second-order entropy is calculated using non-overlapping pairs. As expected, if there are correlations between adjacent symbols, the second-order entropy tends to be lower than the first-order entropy. This indicates that joint coding is able to exploit redundancy better than coding each symbol independently.\n",
        "\n",
        "3. Huffman Coding vs. Joint Huffman Coding:\n",
        "The Huffman coding implementation for single symbols uses the full frequency distribution of individual letters, while the joint coding method treats each pair as a new symbol.\n",
        "\n",
        "For single-symbol Huffman coding, the average codeword length per symbol is often slightly above the first-order entropy.\n",
        "For 2-symbol joint Huffman coding, the average codeword length per symbol is derived from the average bits per pair (divided by 2). In many cases, this average is lower than that for single-symbol coding, demonstrating improved efficiency when the underlying data has patterns that the joint method can exploit.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nc3G8I2AS4b4",
      "metadata": {
        "id": "nc3G8I2AS4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Input Experiments:\n",
            "\n",
            "Experiment 1:\n",
            "Input string: DCDBECEAEBCBAECBBBEEECDABCDCDBAE\n",
            "First-order entropy: 2.2730898459737485\n",
            "Second-order entropy: 1.6875\n",
            "Single-symbol Huffman average length: 2.28125\n",
            "2-symbol joint Huffman average length: 1.6875\n",
            "\n",
            "Experiment 2:\n",
            "Input string: EDDCDDACDCACBCDBDEBACDBAECBDACCD\n",
            "First-order entropy: 2.19616329959714\n",
            "Second-order entropy: 1.6639097655573916\n",
            "Single-symbol Huffman average length: 2.25\n",
            "2-symbol joint Huffman average length: 1.6875\n",
            "\n",
            "Experiment 3:\n",
            "Input string: ACDADAAEEAAABACCECDCCDACBCDCCBAC\n",
            "First-order entropy: 2.1127361177297614\n",
            "Second-order entropy: 1.7264097655573916\n",
            "Single-symbol Huffman average length: 2.1875\n",
            "2-symbol joint Huffman average length: 1.75\n",
            "\n",
            "Experiment 4:\n",
            "Input string: BBCEBAECDABDCEEEADCCCDDBEBAAEBAA\n",
            "First-order entropy: 2.31019159868833\n",
            "Second-order entropy: 1.8125\n",
            "Single-symbol Huffman average length: 2.34375\n",
            "2-symbol joint Huffman average length: 1.8125\n",
            "\n",
            "Experiment 5:\n",
            "Input string: DECAEEEAEEDCADDDBCCBEECEAEDADABA\n",
            "First-order entropy: 2.2222881926787386\n",
            "Second-order entropy: 1.7889097655573916\n",
            "Single-symbol Huffman average length: 2.25\n",
            "2-symbol joint Huffman average length: 1.8125\n",
            "\n",
            "Non-Random Input Experiments:\n",
            "\n",
            "Pattern Experiment 1:\n",
            "Input string: AABBCCAABBCCAABBCCAABBCCAABBCC\n",
            "First-order entropy: 1.584962500721156\n",
            "Second-order entropy: 0.792481250360578\n",
            "Single-symbol Huffman average length: 1.6666666666666667\n",
            "2-symbol joint Huffman average length: 0.8333333333333334\n",
            "\n",
            "Pattern Experiment 2:\n",
            "Input string: ABABABABABABABAB\n",
            "First-order entropy: 1.0\n",
            "Second-order entropy: -0.0\n",
            "Single-symbol Huffman average length: 1.0\n",
            "2-symbol joint Huffman average length: 0.0\n",
            "\n",
            "Pattern Experiment 3:\n",
            "Input string: AAAAAAAABBBBBBBB\n",
            "First-order entropy: 1.0\n",
            "Second-order entropy: 0.5\n",
            "Single-symbol Huffman average length: 1.0\n",
            "2-symbol joint Huffman average length: 0.5\n"
          ]
        }
      ],
      "source": [
        "# (4) Experiment different randomly/non randomly generated inputs, and discuss your observations.\n",
        "# You can implement your experiment here\n",
        "# --- Experiment 1: Randomly Generated Inputs ---\n",
        "import random\n",
        "def experiment_random(n_experiments=5, length=32):\n",
        "    alphabet = ['A', 'B', 'C', 'D', 'E']\n",
        "    print(\"Random Input Experiments:\")\n",
        "    for i in range(n_experiments):\n",
        "        s = ''.join(random.choice(alphabet) for _ in range(length))\n",
        "        print(f\"\\nExperiment {i+1}:\")\n",
        "        print(\"Input string:\", s)\n",
        "        print(\"First-order entropy:\", first_order_entropy(s))\n",
        "        print(\"Second-order entropy:\", second_order_entropy(s))\n",
        "        print(\"Single-symbol Huffman average length:\", huffman_length(s))\n",
        "        print(\"2-symbol joint Huffman average length:\", joint_huffman_length(s))\n",
        "\n",
        "# --- Experiment 2: Non-Random (Patterned) Inputs ---\n",
        "def experiment_patterned():\n",
        "    patterned_strings = [\n",
        "        \"AABBCC\" * 5,    # repeated pattern\n",
        "        \"ABABABABABABABAB\",  # alternating pattern\n",
        "        \"AAAAAAAABBBBBBBB\",  # two blocks of repeated symbols\n",
        "    ]\n",
        "    print(\"\\nNon-Random Input Experiments:\")\n",
        "    for i, s in enumerate(patterned_strings):\n",
        "        print(f\"\\nPattern Experiment {i+1}:\")\n",
        "        print(\"Input string:\", s)\n",
        "        print(\"First-order entropy:\", first_order_entropy(s))\n",
        "        print(\"Second-order entropy:\", second_order_entropy(s))\n",
        "        print(\"Single-symbol Huffman average length:\", huffman_length(s))\n",
        "        print(\"2-symbol joint Huffman average length:\", joint_huffman_length(s))\n",
        "\n",
        "# Run experiments\n",
        "experiment_random()\n",
        "experiment_patterned()\n",
        "\n",
        "\"\"\"\n",
        "Entropy Trends:\n",
        "Across all experiments, the second-order entropy (computed on non-overlapping 2‑symbol pairs) is significantly lower than the first-order entropy. This reduction indicates that there is some predictability between pairs of symbols—i.e., the joint probability distribution captures redundancy not evident when symbols are considered independently.\n",
        "\n",
        "Huffman Coding Performance:\n",
        "\n",
        "The average codeword lengths for single-symbol Huffman coding are very close to the first-order entropy, which is expected since Huffman coding is optimal among prefix codes but still slightly exceeds the entropy bound.\n",
        "The 2-symbol joint Huffman coding average lengths exactly match (or are extremely close to) the second-order entropy in some cases, which confirms that the joint Huffman coding efficiently exploits the redundancy between symbol pairs.\n",
        "Special Case in Experiment 4:\n",
        "In Experiment 4, the observed first-order entropy is 1.0 bit and the second-order entropy is 0.5 bit. These values (with corresponding Huffman lengths matching exactly) suggest that the string has a very skewed or perhaps even binary-like distribution. This case highlights that when the input is highly predictable, both entropy and average codeword lengths drop significantly.\n",
        "\n",
        "Implications:\n",
        "The experiments reinforce the idea that when symbols exhibit dependency (or when certain pairs occur more frequently), 2-symbol joint Huffman coding can achieve a much lower average codeword length per symbol compared to coding symbols individually. The benefit is particularly clear when comparing the 2‑symbol joint average length to the single-symbol Huffman average length.\n",
        "In practical applications, if the data has underlying structure or correlations, joint coding methods can lead to more efficient compression.\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
